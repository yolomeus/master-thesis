\chapter{Introduction}
general retrieval ?
\section{Motivation}
Over the last couple of years, contextualized language representations from deep neural network (DNN) models have become the go-to approach for tackling natural language processing (NLP) tasks. In particular, the \ti{transformer} \cite{vaswani2017attention} and its variants, combined with large-scale, unsupervised pre-training, have shown unprecedented performance in a variety of NLP benchmarks.

However, unlike traditional approaches, these models consist of billions of automatically learned parameters, effectively turning them into huge black box functions. Because of this, understanding why and how such a model arrives at a certain decision, becomes a challenge in itself. Yet, as more and more NLP systems rely on these kinds of models, gaining a better understanding of their internal workings becomes crucial, especially when facing problems such as learned social biases \cite{Nadeem2021StereoSetMS,Bender2021OnTD, kurita2019measuring}, falsely motivated predictions \cite{10.1145/2939672.2939778, DBLP:journals/corr/abs-1802-00614} or simply trying to determine causes of prediction error. In addition, a better understanding might provide insights on model weaknesses and guide model improvement, e.g. when adapting to new domains.

Recent work on understanding neural language models has aimed at measuring the extent, to which certain knowledge is encoded in word representations. For this, a \ti{probing} classifier or \ti{probe} is trained on these representations given a language task. The probe's performance is then expected to reflect how well the representations capture the knowledge required for solving that task.

has recently emerged for nlp, but retrieval which important: google guides how we access information etc

we look at bert, initial break through approach, more recent iterations still similar in essence

\section{Problem Statement}
research question:
\begin{itemize}
    \item given set of tasks, presumably ranking related, which knowledge does bert encode?
    \item how does ranking trained model differ from base language model
    \item can we exploit these differences to inform training for ranking?
\end{itemize}
\section{Contribution}

\section{Thesis Outline}
